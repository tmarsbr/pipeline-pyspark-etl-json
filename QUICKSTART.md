# Guia R√°pido - Pipeline PySpark ETL JSON

## üöÄ In√≠cio R√°pido

### 1. Clone o Reposit√≥rio
```bash
git clone https://github.com/tmarsbr/pipeline-pyspark-etl-json.git
cd pipeline-pyspark-etl-json
```

### 2. Inicie o Cluster Spark
```bash
docker compose up -d
```

### 3. Execute o Pipeline
```bash
# Op√ß√£o mais f√°cil - script automatizado
./run_pipeline.sh

# Ou exemplo simples
./run_pipeline.sh simple
```

### 4. Veja os Resultados
```bash
# Listar arquivos de sa√≠da
ls -lh workspace/output/

# Ver estrutura dos dados processados
tree workspace/output/
```

### 5. Parar o Cluster
```bash
docker compose down
```

## üìä O Que Esperar

### Dados de Entrada
- `workspace/dados/usuarios_api.json` - 5 usu√°rios
- `workspace/dados/transacoes_api.json` - 5 transa√ß√µes
- `workspace/dados/sensores_iot.json` - 5 leituras de sensores

### Dados de Sa√≠da (ap√≥s execu√ß√£o)
- `workspace/output/usuarios/` - Usu√°rios transformados (Parquet)
- `workspace/output/usuarios_csv/` - Usu√°rios transformados (CSV)
- `workspace/output/transacoes/` - Transa√ß√µes transformadas (Parquet)
- `workspace/output/transacoes_por_usuario/` - Agrega√ß√µes por usu√°rio
- `workspace/output/sensores/` - Sensores transformados (Parquet)
- `workspace/output/sensores_agregados/` - Estat√≠sticas dos sensores

## üîç Verificar Status do Cluster

### Spark Master UI
Abra no navegador: http://localhost:9091

### History Server
Abra no navegador: http://localhost:18081

### Via Terminal
```bash
# Ver containers rodando
docker ps

# Ver logs do master
docker logs spark-master

# Ver logs do worker
docker logs dsa-pyspark-cluster-spark-worker-1
```

## üõ†Ô∏è Comandos √öteis

### Executar Manualmente no Container
```bash
# Entrar no container
docker exec -it spark-master bash

# Dentro do container, executar o pipeline
spark-submit --master spark://spark-master:7077 /opt/workspace/jobs/etl_pipeline.py
```

### Escalar Workers
```bash
# Aumentar para 3 workers
docker compose up -d --scale spark-worker=3
```

### Limpar Tudo e Recome√ßar
```bash
# Para e remove containers
docker compose down

# Remove tamb√©m volumes e redes
docker compose down -v

# Reinicia do zero
docker compose up -d
```

## ‚ö†Ô∏è Solu√ß√£o de Problemas

### Container n√£o inicia
```bash
# Ver logs completos
docker compose logs

# Reconstruir imagens
docker compose build --no-cache
docker compose up -d
```

### Porta j√° em uso
Edite o `docker-compose.yml` e altere as portas:
```yaml
ports:
  - "9091:8080"  # Mude 9091 para outra porta dispon√≠vel
```

### Sem espa√ßo em disco
```bash
# Limpar imagens n√£o utilizadas
docker system prune -a
```

## üìö Pr√≥ximos Passos

1. **Adicione seus pr√≥prios dados JSON** em `workspace/dados/`
2. **Modifique as transforma√ß√µes** em `workspace/jobs/etl_pipeline.py`
3. **Crie novas agrega√ß√µes** conforme sua necessidade
4. **Integre com bancos de dados** usando as configura√ß√µes em `config_example.py`

## üí° Dicas

- Use `simple_example.py` para testar rapidamente modifica√ß√µes
- Logs detalhados aparecem no terminal durante a execu√ß√£o
- Formato Parquet √© mais eficiente que CSV para grandes volumes
- Ajuste mem√≥ria dos workers em `docker-compose.yml` conforme necess√°rio

## üìû Suporte

Tiago Mars
- GitHub: [@tmarsbr](https://github.com/tmarsbr)
- LinkedIn: [linkedin.com/in/tiago-dados](https://linkedin.com/in/tiago-dados)
- Email: tiagomars233@gmail.com
